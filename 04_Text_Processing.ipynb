{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8c1a5b-3a5a-447c-b69b-a4afc2e5fc56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcdd7f1-96fd-48fa-b27c-1db763adc564",
   "metadata": {},
   "source": [
    "This notebook uses a collection of Pfizer Vaccine Tweets, available from https://www.kaggle.com/gpreda/pfizer-vaccine-tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3ffc5-5794-42c2-a448-6dcc1f852db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d45e8-2031-4081-bc0b-3ac0492d6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vaccination_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e7cea-6ccd-40c9-b0fc-811b0a12e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c993bca-af37-40c8-90fa-c3aaa4a6e972",
   "metadata": {},
   "source": [
    "### Example: Compare the average number of followers for verified vs. unverified users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2f2fa-6474-4b59-8d89-33a0819953df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('user_verified')['user_followers'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c9c0b-ccf7-4fa4-921e-e95c82cdb2ff",
   "metadata": {},
   "source": [
    "### Challenge: What are some other questions that could be answered by this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a340ba-9a17-4000-8c32-c989c87078c9",
   "metadata": {},
   "source": [
    "Insert your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6a926-2130-4945-ace4-d48b20ccc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933389e2-e93b-493f-8e85-d6a108e8cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0256c-1ea3-4650-90a4-dbd837bd02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe3caa-9704-4246-b69c-475825187de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2621c-a05d-46a2-965e-2443a6f19c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this IS a bad test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e7b19-241b-44e0-b453-8c6902a65c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e444a63f-665b-4e60-97b8-69776c8fd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce159e8e-c24a-4111-9b7b-951a26816c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ad935-a4fa-4f3e-91b3-74aeaa4e8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39e603-2846-4bb9-b991-d759a9b3dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing\n",
    "\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(df['text'].astype('unicode').values, batch_size=50,\n",
    "                        n_threads=6):\n",
    "    if doc.is_parsed:\n",
    "        n_tokens.append(len(doc))\n",
    "        tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        n_tokens.append(0)\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        \n",
    "df['n_tokens'] = n_tokens\n",
    "df['_tokens'] = tokens\n",
    "df['_lemma'] = lemma\n",
    "df['_pos'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f72ded-280a-4bb5-b0f4-fe7e4a898ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da101e84-cb0b-4316-b663-60b2c89bb329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
